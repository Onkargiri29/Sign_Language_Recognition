# Sign Language Recognition using Machine Learning

This repository contains code and resources for Sign Language Recognition using Machine Learning, implemented with TensorFlow and OpenCV in Python. The project aims to create a robust system for recognizing and interpreting sign language gestures using deep learning models.

## Table of Contents
- [Introduction](#introduction)
- [Features](#features)
- [Models](#models)
- [Dataset](#dataset)
- [License](#license)

## Introduction

Sign Language Recognition is a crucial application of machine learning that bridges the communication gap between the hearing-impaired and the rest of the world. This project utilizes deep learning techniques to recognize and translate sign language gestures into text or spoken language.

## Features

- **Real-time Recognition:** The system can recognize sign language gestures in real-time using a webcam.
- **Multiple Gestures:** It supports a variety of sign language gestures, making it versatile and applicable to different sign languages.
- **User-friendly Interface:** The project provides a simple and intuitive interface for users to interact with the recognition system.


## Models

The project leverages TensorFlow for training and deploying machine learning models. Additionally, OpenCV is utilized for image processing and real-time video analysis.

## Dataset

The model is trained on a diverse dataset of sign language gestures. The dataset used for training is available [here](https://github.com/Onkargiri29/Sign_Language_Recognition/tree/main/Data).

## License

This project is licensed under the MIT License - see the [LICENSE](https://github.com/Onkargiri29/Sign_Language_Recognition/blob/main/LICENSE) file for details.
